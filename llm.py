import os  # For accessing environment variables
from dotenv import load_dotenv  # For loading variables from a .env file
import requests  # For sending HTTP requests to the Groq API

# Load environment variables from .env file (like your GROQ_API_KEY)
load_dotenv()

# Get the Groq API key from the environment
groq_api_key = os.getenv("GROQ_API_KEY")

def query_groq(prompt, model="llama3-8b-8192"):
    """
    Sends a prompt to the Groq API using a specified LLM model
    and returns the model's response.

    Parameters:
        prompt (str): The input question or instruction for the model.
        model (str): The name of the Groq-supported LLM model to use.
                     Default is "llama3-8b-8192".

    Returns:
        str: The text response generated by the model.
    """

    # Endpoint for Groq's OpenAI-compatible chat completion API
    url = "https://api.groq.com/openai/v1/chat/completions"

    # Headers including authorization and content type
    headers = {
        "Authorization": f"Bearer {groq_api_key}",  # Use your secret API key
        "Content-Type": "application/json"  # Sending JSON body
    }

    # The data payload sent in the POST request
    data = {
        "model": model,  # e.g., llama3-8b-8192, gemma-7b-it
        "messages": [  # Standard OpenAI-compatible message format
            {"role": "user", "content": prompt}
        ]
    }

    # Make the HTTP POST request to the Groq API
    res = requests.post(url, headers=headers, json=data)

    # Parse the JSON response and extract the generated message content
    return res.json()['choices'][0]['message']['content']
